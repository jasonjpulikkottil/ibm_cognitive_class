{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    " <a href=\"http://cocl.us/DA0101EN_NotbookLink_Top\"><img src = \"https://ibm.box.com/shared/static/fvp89yz8uzmr5q6bs6wnguxbf8x91z35.png\" width = 750, align = \"center\"></a>\n",
    "  <h1 align=center><font size = 5> Link</font></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " <a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width = 300, align = \"center\"></a>\n",
    "\n",
    "<h1 align=center><font size = 5>Data Analysis with Python</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### Recommended, Python for Data Science click to start course:\n",
    "  \n",
    "  <a href=\"http://cocl.us/DA0101ENtoPY0101EN\"><img src = \"https://ibm.box.com/shared/static/jmtb4pgle2dsdlzfmyrgv755cnqw95wk.png\" width = 300, align = \"center\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 Introduction\n",
    "### Welcome!\n",
    "\n",
    "In this section, you will learn how to approach data acquisition in various ways, and obtain necessary insights from a dataset. At the end of this section, you will successfully load/read data into Jupyter Notebook, and get the idea description of dataset via Pandas Library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<li><a href=\"#ref1\">Data Acquisition</a>\n",
    "<li><a href=\"#ref2\">Basic Insight of Dataset</a></li>\n",
    "<p></p>\n",
    "Estimated Time Needed: <strong>10 min</strong>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "# Data Acquisition\n",
    "There are various formats for a dataset, .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.\n",
    "In this section, you will learn how to load/read dataset into our Jupyter Notebook.\n",
    "In our case, the Automobile Dataset is an online source, and it is in CSV (comma separated values) format. Let's use this dataset as an example to practice data reading.\n",
    "data source: https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n",
    "data type: csv\n",
    "The Pandas Library is a useful tool that enables us to read various datasets into a data frame; most Jupyter notebook platforms have a built-in **Pandas Library** so that all we need to do is import it without installing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "We use **\"pandas.read_csv()\"** method to read the csv file. In the bracket, we put the file path along with a quotation mark, so that pandas will read the file into a data frame from that address. The file path can be either an URL or your local file address.\n",
    "Because the row data does not include headers, we can add an argument **\"headers = None\"**  inside the  **\"read_csv()\"** method, so that pandas will not automatically set the first row as a header.\n",
    "You can also assign the dataset to any variable you created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd\n",
    "# read the online file by the URL provides above, and assign it to variable \"df\"\n",
    "path=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "\n",
    "df = pd.read_csv(path,header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click for solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the dataset, we can use **`daraframe.head(n)`** method to check the top n rows of the data frame where n is an integer.Contrary to `dataframe.head(n)`, **`dataframe.tail(n)`** will show you the bottom n rows of data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the first 5 rows by dataframe.head() method\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h1> Question #1: </h1>\n",
    "<b>check the bottom 10 rows of data frame \"df\".</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h1> Question #1 Answer: </h1>\n",
    "<b>Run the code below! Did you get the right code?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <div align=\"right\">\n",
    "<a href=\"#q2\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "\n",
    "</div>\n",
    "<div id=\"q2\" class=\"collapse\">\n",
    "```\n",
    "df.tail(10)\n",
    "```\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Headers\n",
    "Take a look at our dataset; pandas automatically set the header by an integer from 0. \n",
    "<div>\n",
    "To better describe our data we can introduce a header, this information is available at:  https://archive.ics.uci.edu/ml/datasets/Automobile</div>\n",
    "<p></p>\n",
    "<div>Thus, we have to add headers manually.</div>\n",
    "<div>Firstly, we create a list \"headers\" that include all column names in order.</div>\n",
    "<div>Then, we use **`dataframe.columns = headers`** to replace the headers by the list we created.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create headers list\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace headers\n",
    "df.columns = headers\n",
    "\n",
    "# recheck our data frame\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"price\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we successfully read the raw dataset and add the correct headers into the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h1> Question #2: </h1>\n",
    "<b>Find the name of the colunms of the datafram</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div align=\"right\">\n",
    "<a href=\"#q3\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "\n",
    "</div>\n",
    "<div id=\"q3\" class=\"collapse\">\n",
    "```\n",
    "df.columns\n",
    "```\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset\n",
    "Correspondingly, Pandas enable us to save csv dataset by **`dataframe.to_csv()`** method, you can add the file path and name along with quotation mark in the bracket.\n",
    "\n",
    "For example, if you would save the dataframe \"df\" as \"automobile.csv\" to your local machine, you may use the syntax below:\n",
    "~~~~\n",
    "df.to_csv(\"automobile.csv\")\n",
    "~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read/Save Other Data Formats\n",
    "Same as read/save csv file, we use similar methods to read/save other dataset formats:\n",
    "\n",
    "\n",
    "| Data Formate  | Read           | Save             |\n",
    "| ------------- |:--------------:| ----------------:|\n",
    "| csv           | `pd.read_csv()`  |`df.to_csv()`     |\n",
    "| json          | `pd.read_json()` |`df.to_json()`    |\n",
    "| excel         | `pd.read_excel()`|`df.to_excel()`   |\n",
    "| hdf           | `pd.read_hdf()`  |`df.to_hdf()`     |\n",
    "| sql           | `pd.read_sql()`  |`df.to_sql()`     |\n",
    "| ...           |   ...          |       ...        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "# Basic Insight of Dataset\n",
    "After reading data into Pandas dataframe, it is time for us to explore the dataset a little bit.\n",
    "There are several ways to obtain essential insights of dataset, to help us better understand our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "Data has variety of types.\n",
    "The main types stored in pandas objects are `object`, `float`, `int`, `bool` and `datetime64`.In order to better learn about each attributes, it is always good for us to know the data type of each column. In Pandas:\n",
    "~~~~\n",
    "dataframe.dtypes\n",
    "~~~~\n",
    "returns a Series with the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the data type of data frame \"df\" by .dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result shown above, it is clear to see that, the data type of \"symboling\" and \"curb-weight\" are `int64`, \"normalized-losses\" is `object`, and \"wheel-base\" is `float64`, etc.\n",
    "Actually, those data types can be changed on purpose, we will learn that in later module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe\n",
    "If we would like to check the statistical summary of each column, such as records count, column mean value, column standard deviation, etc.\n",
    "~~~~\n",
    "dataframe.describe()\n",
    "~~~~\n",
    "Generates various summary statistics, excluding `NaN` (Not a Number) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use .describe method to get the stat summary of \"df\"\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it shows the statistical summary of all numeric-typed (int, float) columns.\n",
    "For example, attribute \"symboling\" has 205 counts, the mean value of this column is 0.83, the standard deviation is 1.25, the minimum value is -2, 25th percentile is 0, 50th percentile is 1, 75th percentile is 2, and the maximum value is 3.\n",
    "However, what if we would to also check all the columns including other types (such as the object)of data?\n",
    "However, what if we would to also check all the columns including other types (such as `object`) of data?\n",
    "\n",
    "You can add an argument `include = \"all\"` inside the bracket. Let's try it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# describe all the columns in \"df\" \n",
    "df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it provides the statistic summary of all the columns, including object-typed attributes.\n",
    "We can now see how many unique values, which is the top value and the frequency of top value in object-typed columns.\n",
    "Some values in the table above show as \"NaN\", that is because those number is not available regarding particular column type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h1> Question #3: </h1>\n",
    "\n",
    "<p>You can select the columns of a data frame by indicating the name of  each column, for example, you can select the three columns as follows:</p>\n",
    "<p></p>\n",
    "<p>dataframe[[' column 1 ',column 2', 'column 3'] ]</p>\n",
    "<p></p>\n",
    "<p>where \"colums\" is the name of the colum, you can apply the method  \".describe()\" to get the statistics of those columns as follows:</p>\n",
    "<p></p>\n",
    "<p>dataframe[[' column 1 ',column 2', 'column 3'] ].describe() </p>\n",
    "<p></p>\n",
    "\n",
    "Apply the  method to \".describe()\" to the columns 'length'and'compression-ratio'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div align=\"right\">\n",
    "<a href=\"#q4\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "\n",
    "</div>\n",
    "<div id=\"q4\" class=\"collapse\">\n",
    "```\n",
    " df[['length','compression-ratio']].describe()\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info\n",
    "Another method you can use to check your dataset is:\n",
    "~~~~\n",
    "dataframe.info\n",
    "~~~~\n",
    "It provide a concise summary of your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the info of \"df\"\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are able to see the information of our data frame, with top 30 rows and bottom 30 rows.\n",
    "\n",
    "And, it also shows us the whole data frame has 205 rows and 26 columns in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excellent! You have just completed the  Introduction  Notebook! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### About the Authors:  \n",
    "\n",
    "This notebook written by [Mahdi Noorian PhD](https://www.linkedin.com/in/mahdi-noorian-58219234/) ,[Joseph Santarcangelo PhD]( https://www.linkedin.com/in/joseph-s-50398b136/), Bahare Talayian, Eric Xiao, Steven Dong, Parizad , Hima Vsudevan and [Fiorella Wenver](https://www.linkedin.com/in/fiorellawever/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright &copy; 2017 [cognitiveclass.ai](cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    " <a href=\"http://cocl.us/DA0101EN_NotbookLink_bottom\"><img src = \"https://ibm.box.com/shared/static/cy2mwm7519t4z6dxefjpzgtbpi9p8l7h.png\" width = 750, align = \"center\"></a>\n",
    " <h1 align=center><font size = 5> Link</font></h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
